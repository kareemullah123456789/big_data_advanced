{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kareemullah123456789/big_data_advanced/blob/main/pyspark_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4abc7a6",
      "metadata": {
        "id": "f4abc7a6"
      },
      "source": [
        "# PySpark vs Pandas Tutorial\n",
        "\n",
        "This notebook provides an easy-to-understand comparison between Pandas and PySpark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aecc3207",
      "metadata": {
        "id": "aecc3207"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName(\"PySpark_Tutorial\").getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "684fafbd",
      "metadata": {
        "id": "684fafbd"
      },
      "source": [
        "## 1. Reading CSV Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d12d0642",
      "metadata": {
        "id": "d12d0642"
      },
      "outputs": [],
      "source": [
        "df_pandas = pd.read_csv(\"data.csv\")\n",
        "print(\"Pandas DataFrame:\")\n",
        "display(df_pandas.head())\n",
        "\n",
        "df_spark = spark.read.csv(\"data.csv\", header=True, inferSchema=True)\n",
        "df_spark.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f3b2bcf",
      "metadata": {
        "id": "3f3b2bcf"
      },
      "source": [
        "## 2. Filtering Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4d52527",
      "metadata": {
        "id": "f4d52527"
      },
      "outputs": [],
      "source": [
        "df_pandas_filtered = df_pandas[df_pandas['age'] > 30]\n",
        "display(df_pandas_filtered)\n",
        "\n",
        "df_spark_filtered = df_spark.filter(df_spark['age'] > 30)\n",
        "df_spark_filtered.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "beb40870",
      "metadata": {
        "id": "beb40870"
      },
      "source": [
        "## 3. Grouping Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd7ae44c",
      "metadata": {
        "id": "cd7ae44c"
      },
      "outputs": [],
      "source": [
        "df_pandas_grouped = df_pandas.groupby(\"department\")[\"salary\"].mean()\n",
        "display(df_pandas_grouped)\n",
        "\n",
        "df_spark_grouped = df_spark.groupBy(\"department\").agg({\"salary\": \"avg\"})\n",
        "df_spark_grouped.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2b06f7b",
      "metadata": {
        "id": "a2b06f7b"
      },
      "source": [
        "## 4. SQL Queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "772ad3fe",
      "metadata": {
        "id": "772ad3fe"
      },
      "outputs": [],
      "source": [
        "df_spark.createOrReplaceTempView(\"employees\")\n",
        "sql_result = spark.sql(\"SELECT name, age FROM employees WHERE age > 30\")\n",
        "sql_result.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8376ec4a",
      "metadata": {
        "id": "8376ec4a"
      },
      "source": [
        "## 5. Adding a New Column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b9d4df6",
      "metadata": {
        "id": "3b9d4df6"
      },
      "outputs": [],
      "source": [
        "df_pandas[\"salary_increase\"] = df_pandas[\"salary\"] * 1.10\n",
        "display(df_pandas.head())\n",
        "\n",
        "df_spark = df_spark.withColumn(\"salary_increase\", df_spark[\"salary\"] * 1.10)\n",
        "df_spark.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66f32d4b",
      "metadata": {
        "id": "66f32d4b"
      },
      "source": [
        "## 6. Handling Missing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b1c5064",
      "metadata": {
        "id": "1b1c5064"
      },
      "outputs": [],
      "source": [
        "df_pandas.dropna()\n",
        "df_spark.dropna().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9565d877",
      "metadata": {
        "id": "9565d877"
      },
      "source": [
        "## 7. Window Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be7822a9",
      "metadata": {
        "id": "be7822a9"
      },
      "outputs": [],
      "source": [
        "windowSpec = Window.partitionBy(\"department\").orderBy(\"salary\")\n",
        "df_spark = df_spark.withColumn(\"rank\", rank().over(windowSpec))\n",
        "df_spark.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67db9154",
      "metadata": {
        "id": "67db9154"
      },
      "source": [
        "## 8. Joins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c333eec9",
      "metadata": {
        "id": "c333eec9"
      },
      "outputs": [],
      "source": [
        "df1_spark = df_spark.alias(\"df1\")\n",
        "df2_spark = df_spark.alias(\"df2\")\n",
        "df_joined = df1_spark.join(df2_spark, df1_spark.id == df2_spark.id, \"inner\")\n",
        "df_joined.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a639d5f",
      "metadata": {
        "id": "3a639d5f"
      },
      "source": [
        "## 9. Data Partitioning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f2e9295",
      "metadata": {
        "id": "2f2e9295"
      },
      "outputs": [],
      "source": [
        "df_spark_repartitioned = df_spark.repartition(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00d1e9de",
      "metadata": {
        "id": "00d1e9de"
      },
      "source": [
        "## 10. Caching Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e9f1a7f",
      "metadata": {
        "id": "8e9f1a7f"
      },
      "outputs": [],
      "source": [
        "df_spark.cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1719fc2",
      "metadata": {
        "id": "b1719fc2"
      },
      "source": [
        "## Stopping Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "958f9044",
      "metadata": {
        "id": "958f9044"
      },
      "outputs": [],
      "source": [
        "spark.stop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}